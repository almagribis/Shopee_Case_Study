{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd76c8b",
   "metadata": {},
   "source": [
    "# Engineering Knowledge AI Agent Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1b7cd",
   "metadata": {},
   "source": [
    "1. Describe differences between REST API, MCP in the context of AI.\n",
    "\n",
    "- REST API is a web service interface that enables different systems to communicate and exchange data and perform operation via standards HTTP methods. In AI context, REST API can use to serve AI models (Computer Vision, NLP and LLM) as the inference services. In context of AI Agent development, REST API can also connect the AI Agents with external data sources or tools like google search, vector database, application or even to communicate with other agent in multi agents concept.\n",
    "\n",
    "- MCP (Multi Context Protocol) is a new standard introduced by Anthropic to simplify and unify how AI models especially LLM interract with external data sources and tools. This protocols enable AI systems to access and select right tools or external sources in uniform way making integration and development process more streamlined.\n",
    "\n",
    "- The differences between both REST API and MCP lie in their purpose, integration process and maintenance. REST API are general web service that often require developers to customize or builf from scratch, which can be time consuming. MCP offers a uniform, standardize and faster approach for integrating AI Agent with other sources. However MCP is still relatively limited on platform support compare to REST API ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f2ebf",
   "metadata": {},
   "source": [
    "2. How REST API, MCP, can improve the AI use case.\n",
    "- REST API can improve AI use case by enabling inferencces for various AI models that interract with multiple types of data such as text, images and audio. In terms of scalability REST API can easily manage by using a load balancer. Integration with existing application especially web is easier because it use HTTP methode. In building AI Agents, REST API can use serve the AI Agent for inference service also to connect agent with various external data sources and tools. It will be requires effort during the initial integration process but will be very helpful in maintenance and versioning for each tools without affecting the main AI Agent.\n",
    "- MCP can improve both in process and contextual in AI Agent workflow. Each tool or external data sources can be connect quickly because there is already a standard and simple protocol that only require prompt adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ba7dc",
   "metadata": {},
   "source": [
    "3. How do you ensure that your AI agent answers correctly?\n",
    "- Understanding context before development. Befor develop an AI Agent, as engineer we must fully understand the domain and goals of the agent including data sources, capabilities and the target users. This helps us to design effective prompts such as system prompt and tools descriptions so the agent can select the most relevant tools.\n",
    "- Build the knowledge base. When createing a knowledge base in vector database, it's important to consider the chunking method and the coice of embedding model whether the documents are mono or multi language. Adding metadata to vector database to enable hybrid search, making retrieval results more focused and accurate. We can also use time-weighted retrieval approach if the document is dynamic to ensure the more recent data get higher priority. After retrieval, we can adding a reranking step to helps order the documents.\n",
    "- Agent design. We can choose agent strategy based on the complexity of tasks and data variation such as simple RAG, AI Agent with planning or chain of tought approach or even Agentic AI. We can also use a specific function as tools such as a machine learning model inference or other specific calculation to enhance the answer.\n",
    "- Selecting models and adjust parameter. Choose the most suitable LLM and adjust the parameters according the agent context. Creative, exact, analytic or strategic task each could require different LLM and parameter settings to achieve best outcomes. If needed we could fine tune the LLM if the agent will operate in very specific domain.\n",
    "- Applying guardrails and evaluation. Implement guardrails to limit unwanted behaviour and reduce bias in agent responses. We can evaluat LLM by manual feedback from user and also automated assesments using LLM as a judge approach. Evaluation needs to help identify the weekness and guide necessary improvements.\n",
    "- Continues improvement. There are many possible method to ensure the agent answer correctly and not all must be used at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7df8d",
   "metadata": {},
   "source": [
    "4. Describe what can you do with Docker / Containerize environment in the context of AI\n",
    "- Docker and containerized environment allow developers to package and deploy AI models or AI Agents more easily and consistent across different systems. With docker we can ensure that AI application runs in identical environment whether on a local computer, on prem server or  cloud platform. This helps speed up the installation process by avoiding dependency issues.\n",
    "- Containerization also supports better maintenance and versioning, making it easier to perform updates or rollbacks when needed.\n",
    "- Docker enhances scalability as AI model or agent can be deploy as microservices supported by load balancer or even managed through Kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9a095",
   "metadata": {},
   "source": [
    "5. How do you finetune the LLM model from raw ?\n",
    "- Understand the domain. Similar to developing AI Agentm, fine tune LLM does not start with engineering but with understanding the goals and the data. We need to clearly define what to achieve and identify the tasks whether for QnA, Legal, Targeted Sentiment Analysis with reasoning and others. This helps determine the base LLM, choose LLM parameters and fine tune approach to be used.\n",
    "- Prepare raw data for fine tune ready. If the data is not yet ready for fine tuning, we must prepare it properly. This can involve manual annotation or using distillation approach with existing LLM to generate labeled data if needed.\n",
    "- Select fine tune methode. There are several methode to choose based oon resources and objectives. Unsupervised finetune to expose model to domain specific terms and context. Supervised finetune to train the model on specific tasks and expected output. PEFT or LoRA for limited computational resources but modular.\n",
    "- Evaluate the finetuned model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
